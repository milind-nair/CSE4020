{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3559907118.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\nairm\\AppData\\Local\\Temp\\ipykernel_25740\\3559907118.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    Find S\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Find S\n",
    "import pandas as pd\n",
    "dataset = pd.read_csv('enjoysport.csv')\n",
    "dataset\n",
    "dataset = dataset.values.tolist()\n",
    "rows = len(dataset)\n",
    "columns = len(dataset[0])-1\n",
    "hypothesis = [\"phi\"]*columns\n",
    "print(\"The initial hypothesis is : h[0] = \", hypothesis )\n",
    "print()\n",
    "for i in range(0,rows):\n",
    "    print(\"Instance {} is {}\".format(i+1,dataset[i]))\n",
    "    if(dataset[i][columns]==\"Yes\"):\n",
    "        if hypothesis[0]==\"phi\":\n",
    "            for j in range(0,columns):\n",
    "                hypothesis[j]=dataset[0][j]\n",
    "        for j in range(columns):\n",
    "            if(dataset[i][j]!=hypothesis[j]):\n",
    "                hypothesis[j]=\"?\"\n",
    "    print (\"h[{}] = {}\".format(i+1,hypothesis))\n",
    "    print(\"\\n\")\n",
    "print(\"The Final Hypothesis is  : {}\".format(hypothesis))\n",
    "\n",
    "Candidate Elimination\n",
    "import pandas as pd\n",
    "dataset=[]\n",
    "dataset = pd.read_csv('enjoysport.csv')\n",
    "dataset = dataset.values.tolist()\n",
    "rows = len(dataset)\n",
    "columns = len(dataset[0])-1\n",
    "dataset\n",
    "S=['0']*columns\n",
    "G=['?']*columns\n",
    "print(\"The most specific hypothesis is : S = \", S )\n",
    "print(\"The most general hypothesis is : G = \", G )\n",
    "print()\n",
    "temp=[]\n",
    "for i in range(0,len(dataset)):\n",
    "    if dataset[i][columns] == \"Yes\" :\n",
    "        if S[0]==\"0\":\n",
    "            for j in range(0,columns):\n",
    "                S[j]=dataset[0][j]\n",
    "        for j in range(0,columns):\n",
    "            if S[j] != dataset[i][j]:\n",
    "                S[j]=\"?\"\n",
    "        for j in range(0, columns):\n",
    "            for k in range(0,len(temp)):\n",
    "                if temp[k][j] != S[j] and temp[k][j] !=\"?\" :\n",
    "                    del temp[k]\n",
    "    if dataset[i][columns]== \"No\":\n",
    "        for j in range(0,columns):\n",
    "            if dataset[i][j] != S[j] and S[j] !=\"?\" :\n",
    "                G[j] = S[j]\n",
    "                temp.append(G)\n",
    "                G=[\"?\"]*columns\n",
    "    print(\"Instance {} is {}\".format(i+1,dataset[i]))\n",
    "    print (\"S[{}] = {}\".format(i+1,S))\n",
    "    if len(temp)==0:\n",
    "        print(\"G[{}] = {}\".format(i+1,G))\n",
    "    else:\n",
    "        print(\"G[{}] = {}\".format(i+1,temp))\n",
    "    print()\n",
    "\n",
    "print(\"The Final S is  : {}\".format(S))\n",
    "if len(temp)==0:\n",
    "    print(\"The Final G is  : {}\".format(G))\n",
    "else:\n",
    "    print(\"The Final G is  : {}\".format(temp))\n",
    "\n",
    "Simple LR\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import mean_squared_error \n",
    "dataset = pd.read_csv(\"heightsandweights.csv\")\n",
    "dataset\n",
    "x = dataset.iloc[:,0:-1].values\n",
    "print(\"Training Attribute x =\")\n",
    "print(*x,sep=\",\") \n",
    "print()\n",
    "xtrain = x[0:-1]\n",
    "print(\"XTrain =\")\n",
    "print(*xtrain,sep=\",\")\n",
    "xtest = x[-1]\n",
    "xtest = xtest.reshape(-1, 1)\n",
    "print()\n",
    "print(\"XTest =\")\n",
    "print(*xtest,sep=\",\")\n",
    "y = dataset.iloc[:,-1].values\n",
    "print(\"Test Attribute y =\")\n",
    "print(*y,sep=\",\") \n",
    "print()\n",
    "ytrain = y[0:-1]\n",
    "print(\"YTrain =\")\n",
    "print(*ytrain,sep=\",\")\n",
    "ytest = y[-1]\n",
    "print()\n",
    "print(\"YTest =\")\n",
    "print(ytest,sep=\",\")\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(xtrain,ytrain)\n",
    "y_pred = regressor.predict(xtest)\n",
    "print(\"The predicted y value is : ypred = \", *y_pred)\n",
    "print(\"The coefficient w1 = \" , *regressor.coef_)\n",
    "print(\"The coefficient w0 = \" , regressor.intercept_)\n",
    "df= pd.DataFrame()\n",
    "df[\"y_actual\"] = [ytest]\n",
    "df[\"y_predicted\"] = y_pred\n",
    "df\n",
    "print(\"The Mean Squared Error is : \" , mean_squared_error([ytest],y_pred))\n",
    "loss = ytest - y_pred\n",
    "print(\"The loss is : \" ,*loss)\n",
    "plt.scatter(xtrain,ytrain)\n",
    "plt.plot(xtrain,regressor.predict(xtrain))\n",
    "plt.show()\n",
    "\n",
    "Multiple LR \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import mean_squared_error \n",
    "dataset = pd.read_csv(\"multiplelr.csv\")\n",
    "dataset\n",
    "x = dataset.iloc[:,1:].values\n",
    "print(\"Training Attribute x =\")\n",
    "print(*x,sep=\",\") \n",
    "y = dataset.iloc[:,0].values\n",
    "print(\"Test Attribute y =\")\n",
    "print(*y,sep=\",\") \n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.16, random_state=0)\n",
    "print(\"XTrain =\")\n",
    "print(*x_train,sep=\",\")\n",
    "xtest = x_test.reshape(-1, 1)\n",
    "print()\n",
    "print(\"XTest =\")\n",
    "print(*x_test,sep=\",\")\n",
    "print()\n",
    "print(\"YTrain =\")\n",
    "print(*y_train,sep=\",\")\n",
    "print()\n",
    "print(\"YTest =\")\n",
    "print(y_test,sep=\",\")\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(x_train,y_train)\n",
    "y_pred = regressor.predict(x_test)\n",
    "print(\"The coefficient w1 = \" , regressor.coef_[0])\n",
    "print(\"The coefficient w2 = \" , regressor.coef_[1])\n",
    "print(\"The coefficient w0 = \" , regressor.intercept_)\n",
    "print(\"The predicted y value is : ypred = \", *y_pred)\n",
    "print(\"The Mean Squared Error is : \" , mean_squared_error([y_test],y_pred))\n",
    "loss = y_test - y_pred\n",
    "print(\"The loss is : \" ,*loss)\n",
    "\n",
    "Logistic Regression\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "dataset = pd.read_csv(\"logistic.csv\")\n",
    "dataset\n",
    "x = dataset.iloc[:,:-1].values\n",
    "print(\"Training Attribute x =\")\n",
    "print(*x,sep=\",\") \n",
    "y = dataset.iloc[:,-1].values\n",
    "print(\"Test Attribute y =\")\n",
    "print(y,sep=\",\") \n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=0)\n",
    "print(\"XTrain =\")\n",
    "print(*x_train,sep=\",\")\n",
    "xtest = x_test.reshape(-1, 1)\n",
    "print()\n",
    "print(\"XTest =\")\n",
    "print(*x_test,sep=\",\")\n",
    "print()\n",
    "print(\"YTrain =\")\n",
    "print(*y_train,sep=\",\")\n",
    "print()\n",
    "print(\"YTest =\")\n",
    "print(y_test,sep=\",\")\n",
    "clf = LogisticRegression(random_state=0).fit(x_train, y_train)\n",
    "predictions = clf.predict(x_test[0:])\n",
    "predictions\n",
    "score = clf.score(x_test, y_test)\n",
    "print(score)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "cm = metrics.confusion_matrix(y_test, predictions)\n",
    "print(cm)\n",
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "all_sample_title = 'Accuracy Score: {0}'.format(score)\n",
    "plt.title(all_sample_title, size = 15);\n",
    "\n",
    "Decision Tree\n",
    "import pandas as pd \n",
    "dataset = pd.read_csv(\"playtennis.csv\")\n",
    "dataset = dataset.iloc[:,1:]\n",
    "dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "Le = LabelEncoder()\n",
    "dataset['Outlook'] = Le.fit_transform(dataset['Outlook'])\n",
    "dataset['Temp'] = Le.fit_transform(dataset['Temp'])\n",
    "dataset['Humidity'] = Le.fit_transform(dataset['Humidity'])\n",
    "dataset['Wind'] = Le.fit_transform(dataset['Wind'])\n",
    "dataset['PlayTennis?'] = Le.fit_transform(dataset['PlayTennis?'])\n",
    "dataset\n",
    "y = dataset[\"PlayTennis?\"]\n",
    "X = dataset.drop([\"PlayTennis?\"],axis=1)\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier(criterion = 'entropy')\n",
    "clf = clf.fit(X, y)\n",
    "tree.plot_tree(clf)\n",
    "import graphviz \n",
    "dot_data = tree.export_graphviz(clf, out_file=None) \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph\n",
    "\n",
    "kNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "dataset = pd.read_csv(\"knn.csv\")\n",
    "X = dataset.iloc[:,:-1]\n",
    "y = dataset.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "\t\t\tX, y, test_size = 0.1, random_state=42)\n",
    "neighbors = np.arange(1, 9)\n",
    "train_accuracy = np.empty(len(neighbors))\n",
    "test_accuracy = np.empty(len(neighbors))\n",
    "for i, k in enumerate(neighbors):\n",
    "\tknn = KNeighborsClassifier(n_neighbors=k)\n",
    "\tknn.fit(X_train, y_train)\t\n",
    "\t# Compute training and test data accuracy\n",
    "\ttrain_accuracy[i] = knn.score(X_train, y_train)\n",
    "\ttest_accuracy[i] = knn.score(X_test, y_test)\n",
    "plt.plot(neighbors, test_accuracy, label = 'Testing dataset Accuracy')\n",
    "plt.plot(neighbors, train_accuracy, label = 'Training dataset Accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('n_neighbors')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n",
    "\n",
    "kNN Hardcode\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_csv(\"knn.csv\")\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "def euclidean_distance(a, b):\n",
    "    dim = len(a)\n",
    "    distance = 0\n",
    "    for d in range(dim):\n",
    "        distance += abs(a[d] - b[d])**2\n",
    "    return distance**(1/2)\n",
    "euclidean_distance(a=X.iloc[0], b=X.iloc[9])\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25,\n",
    "                                                   random_state=1)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "def knn_predict(X_train, X_test, y_train, y_test, k):    \n",
    "    y_hat_test = []\n",
    "    for test_point in X_test:\n",
    "        distances = []\n",
    "        for train_point in X_train:\n",
    "            distance = euclidean_distance(test_point, train_point)\n",
    "            distances.append(distance)\n",
    "        df_dists = pd.DataFrame(data=distances, columns=['dist'], \n",
    "                                index=y_train.index)\n",
    "        df_nn = df_dists.sort_values(by=['dist'], axis=0)[:k]\n",
    "        counter = Counter(y_train[df_nn.index])\n",
    "        prediction = counter.most_common()[0][0]\n",
    "        y_hat_test.append(prediction)        \n",
    "    return y_hat_test\n",
    "y_hat_test = knn_predict(X_train, X_test, y_train, y_test, k=2)\n",
    "print(y_hat_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_hat_test))\n",
    "accuracies = []\n",
    "for k in range(1,10):\n",
    "    y_hat_test = knn_predict(X_train, X_test, y_train, y_test, k)\n",
    "    accuracies.append(accuracy_score(y_test, y_hat_test))\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax.plot(range(1,10), accuracies)\n",
    "ax.set_xlabel('# of Nearest Neighbors (k)')\n",
    "ax.set_ylabel('Accuracy (%)');\n",
    "\n",
    "SVM Linear\n",
    "from sklearn import svm\n",
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('linearsvm.csv')\n",
    "data\n",
    "X = data[['x1', 'x2']].values\n",
    "y = data['y'].values\n",
    "model = svm.SVC(kernel='linear', C=1)\n",
    "model.fit(X, y)\n",
    "# Plotting the decision boundary\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=30, cmap=plt.cm.Paired)\n",
    "ax = plt.gca()\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "\n",
    "# Creating a grid to evaluate the model\n",
    "xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "Z = model.decision_function(xy).reshape(XX.shape)\n",
    "\n",
    "# Plotting the decision boundary and margins\n",
    "ax.contour(XX, YY, Z, colors='k', levels=[-1, 0, 1], alpha=0.5, linestyles=['--', '-', '--'])\n",
    "ax.scatter(model.support_vectors_[:, 0], model.support_vectors_[:, 1], s=100, linewidth=1, facecolors='none', edgecolors='k')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "Non Linear SVM\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Read the CSV file into a pandas dataframe\n",
    "df = pd.read_csv('svmnonlinear.csv')\n",
    "df\n",
    "X = df[['x1', 'x2']].values\n",
    "y = df['y'].values\n",
    "# Create a non-linear SVM classifier with a Polynomial kernel\n",
    "clf = SVC(kernel='poly', gamma='scale',degree=2)\n",
    "\n",
    "# Train the SVM classifier on the training data\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Visualize the data and the decision boundary\n",
    "x1 = np.linspace(-2, 2, 100)\n",
    "x2 = np.linspace(-2,2, 100)\n",
    "xx1, xx2 = np.meshgrid(x1, x2)\n",
    "Z = clf.decision_function(np.c_[xx1.ravel(), xx2.ravel()])\n",
    "Z = Z.reshape(xx1.shape)\n",
    "\n",
    "plt.contourf(xx1, xx2, Z, levels=[-1, 0, 1], alpha=0.5, colors=['blue', 'red'])\n",
    "plt.contour(xx1, xx2, Z, levels=[-1, 0, 1], linestyles=['--', '-', '--'], colors='k')\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired, edgecolors='black')\n",
    "plt.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1], s=100, facecolors='none', edgecolors='black')\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.title('Non-linear SVM')\n",
    "plt.show()\n",
    "\n",
    "KMeans\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "# Read the CSV file into a pandas dataframe\n",
    "df = pd.read_csv('Mall_Customers.csv')\n",
    "df\n",
    "X = df[[\"Annual Income (k$)\",\"Spending Score (1-100)\"]]\n",
    "X.head()\n",
    "wcss = []\n",
    "for i in range(1,11):\n",
    "    kmeans = KMeans(n_clusters=i)\n",
    "    kmeans.fit(X)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(range(1,11),wcss)\n",
    "plt.plot(range(1,11),wcss,linewidth=2,color=\"red\",marker=\"8\")\n",
    "plt.xlabel(\"K Value\")\n",
    "plt.xticks(np.arange(1,11,1))\n",
    "plt.ylabel(\"WCSS\")\n",
    "plt.show()\n",
    "Optimum Number of Clusters = 5 \n",
    "kmeans1 = KMeans(n_clusters=5)\n",
    "kmeans1.fit(X)\n",
    "y= kmeans1.predict(X)\n",
    "df[\"label\"]=y\n",
    "df\n",
    "#Scatterplot of the clusters\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(x = 'Annual Income (k$)',y = 'Spending Score (1-100)',hue=\"label\",  \n",
    "                 palette=['green','orange','brown','dodgerblue','red'], legend='full',data = df  ,s = 60 )\n",
    "plt.xlabel('Annual Income (k$)')\n",
    "plt.ylabel('Spending Score (1-100)') \n",
    "plt.title('Spending Score (1-100) vs Annual Income (k$)')\n",
    "plt.scatter(kmeans1.cluster_centers_[:, 0], kmeans1.cluster_centers_[:, 1], s=150, c='black')\n",
    "plt.show()\n",
    "\n",
    "KModes\n",
    "from kmodes.kmodes import KModes\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "# Read the CSV file into a pandas dataframe\n",
    "df = pd.read_csv('Mall_Customers.csv')\n",
    "df\n",
    "X = df[[\"Annual Income (k$)\",\"Spending Score (1-100)\"]]\n",
    "X.head()\n",
    "wcss = []\n",
    "for i in range(1,11):\n",
    "    kmodes = KModes(n_clusters=i)\n",
    "    kmodes.fit_predict(X)\n",
    "    wcss.append(kmodes.cost_)\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(range(1,11),wcss)\n",
    "plt.plot(range(1,11),wcss,linewidth=2,color=\"red\",marker=\"8\")\n",
    "plt.xlabel(\"K Value\")\n",
    "plt.xticks(np.arange(1,11,1))\n",
    "plt.ylabel(\"WCSS\")\n",
    "plt.show()\n",
    "kmodes1 = KModes(n_clusters=8)\n",
    "kmodes1.fit_predict(X)\n",
    "y= kmodes1.predict(X)\n",
    "df[\"label\"]=y\n",
    "df\n",
    "#Scatterplot of the clusters\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(x = 'Annual Income (k$)',y = 'Spending Score (1-100)',hue=\"label\", palette= [ 'red', 'orange', 'Brown', 'Yellow', 'Green', 'Turquoise', 'Blue', 'Violet']\n",
    "                  ,legend='full',data = df  ,s = 60 )\n",
    "plt.xlabel('Annual Income (k$)')\n",
    "plt.ylabel('Spending Score (1-100)') \n",
    "plt.title('Spending Score (1-100) vs Annual Income (k$)')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
